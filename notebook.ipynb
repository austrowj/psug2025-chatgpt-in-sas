{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Hello! This is the jupyter notebook version of the paper.\n",
    "# You will need to install and configure SASpy to run the notebook. Please refer to the SASpy documentation.\n",
    "# You will likely also need to change most of the references to local files to get the notebook to run.\n",
    "#\n",
    "# Alternatively, the full SAS code is also in a separate file which you can use directly from within SAS.\n",
    "#\n",
    "\n",
    "import saspy\n",
    "sas = saspy.SASsession(cfgfile='conf/sascfg.py', results='HTML')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperNumber\"}\n",
    "PharmaSUG 2025 - Paper AI-286\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperTitle\"}\n",
    "Get Started with ChatGPT and DeepSeek in SAS\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"Style PaperAuthor + Arial\"}\n",
    "James Austrow, Cleveland Clinic\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "If you've been feeling like a wallflower at the LLM party, this paper is for you.\n",
    "Whether you're intimidated by the jargon, a SAS programmer marooned in a sea of Python tutorials, or simply don't know where to begin, you'll find your answers here.\n",
    "\n",
    "Follow along with this walkthough to build, from scratch, the foundations of an AI-powered SAS application.\n",
    "You'll get properly acquainted with the language model lingo: prompt engineering, zero-shot, few-shot, chain-of-thought, and prompt chaining all receive practical treatment.\n",
    "Don't just have them explained, see how you can apply them to solve a real data processing problem.\n",
    "\n",
    "The AI landscape is constantly evolving.\n",
    "Two of the most well-known language model services, ChatGPT and DeepSeek, receive specific focus here, but the concepts are generalizable and apply to all the major providers.\n",
    "\n",
    "Advanced SAS users stand to get the most out of this paper.\n",
    "However, anyone, even non-programmers, with an interest in prompt engineering may benefit as well.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "It's now 2025, and large language models like ChatGPT are no longer the new kid on the block.\n",
    "Though they still seem magical in many ways, their use cases and limitations are much better understood than just a few years ago.\n",
    "The market has also matured significantly, with no shortage of competing platforms surfacing since OpenAI publicly debuted the core technology in late 2022.\n",
    "That's not even to mention the homebrew possibilities enabled by self-hosting your own model, provided you have a beefy enough GPU.\n",
    "\n",
    "For a software developer or programmer looking to build applications on top of language models, there has never been a better time to get started.\n",
    "Prompt engineering is becoming a distinct skillset with its own principles, concepts, and complexities.\n",
    "There are generalizable techniques and a plethora of resources to learn from.\n",
    "\n",
    "Despite these advances in the ecosystem, relatively little guidance oriented towards the SAS user community seems to exist.\n",
    "This paper aims to address that gap.\n",
    "Consider it your starter kit for working with language model APIs in SAS.\n",
    "\n",
    "There is first the technical matter of actually getting a prompt round-trip to and from a model.\n",
    "You'll work out the basic mechanics in the \"Fundamentals\" section.\n",
    "Next, \"Building Your Own API Client\" will walk through how to abstract those details behind a friendly user (programmer) interface.\n",
    "It will be helpful to have an advanced understanding of SAS for these sections.\n",
    "\n",
    "In the second half, you'll get a crash course in prompt engineering as you try to get the language model to perform date imputation for you.\n",
    "This will provide a survey of the basic techniques and vocabulary to help you later navigate advanced prompt engineering resources on your own.\n",
    "No particular prerequisites are assumed for this section, and anyone (even non-programmers) should be able to benefit from it.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### A Word on Data Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "It would be remiss to fail to remind you of the inherent danger of interacting with language model platforms.\n",
    "You can be quite certain that any material you submit as part of a prompt will be used to help train an AI product or be otherwise mined for information.\n",
    "As such, remember to __only send text that you wouldn't care if it became public__.\n",
    "This is doubly important when using a platform controlled by a foreign country.\n",
    "\n",
    "That said, language models are very powerful and quite rewarding to experiment with.\n",
    "They are absolutely worth exploring provided you keep the above warning in mind.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining an API Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "Before anything else, you must obtain an API key. You can do so at these locations after logging in to the platform:\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"List Bullet\"}\n",
    "For ChatGPT: [https://platform.openai.com/api-keys](https://platform.openai.com/api-keys)\n",
    "\n",
    "For DeepSeek: [https://platform.deekseek.com/api_keys](https://platform.deekseek.com/api_keys)\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "Regardless of which platform you use, you will also need to fund your account.\n",
    "Neither service has a free tier for its API but fortunately, both have extremely cheap models available.\n",
    "As little as a single U.S dollar will last you a long time.\n",
    "\n",
    "Keep in mind that the API key is the only information used by the platform to authenticate your requests.\n",
    "If someone else gets ahold of it, they can impersonate you.\n",
    "Hence, it's important to avoid accidentally leaking your key.\n",
    "The most common way this happens is by writing the key directly into your program.\n",
    "A better practice is to read the key from an external file instead.\n",
    "\n",
    "Create a file with your API key as its only contents, then read the key into SAS like this:\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%SAS sas\n",
    "data _null_;\n",
    "    infile \"sources/api_key_chatgpt.txt\" length=len;\n",
    "    input contents $varying2000. len;\n",
    "    call symputx(\"api_key\", contents);\n",
    "run;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"Caption\"}\n",
    "Program: Loading an API key from an external file.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "A macro variable is a convenient place to store the key, but watch out!\n",
    "If you have the MPRINT option enabled, your key will be printed to the program log in plaintext.\n",
    "You may prefer to use a different technique if this will be a problem for you.\n",
    "\n",
    "The other common way that keys are leaked is by committing the file that contains them to version control.\n",
    "This is potentially much worse if your repository is somewhere on the public internet, such as Github.\n",
    "If you ever leak your key, you can always just delete it using the OpenAI or DeepSeek dashboard, so staying vigilant will usually prevent any serious consequences.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sending Your First Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "It's time to introduce yourself!\n",
    "This example uses the OpenAI API, but the DeepSeek API is fully compatible and shares the same request format (DeepSeek 2025).\n",
    "\n",
    "You can construct and send a request manually in SAS using PROC HTTP (Henry 2019).\n",
    "The most complex piece of the request is the JSON body.\n",
    "Create that separately by using the FILE statement:\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%SAS sas\n",
    "filename req_json TEMP; /* Name has to be 8 characters or less. */\n",
    "data _null_;\n",
    "    file req_json recfm=f lrecl=1;\n",
    "\n",
    "    put '{';\n",
    "    put     '\"model\": \"gpt-4o-mini\",';\n",
    "    put     '\"messages\": [';\n",
    "    put         '{';\n",
    "    put             '\"role\": \"user\",';\n",
    "    put             '\"content\": [';\n",
    "    put                 '{ \"type\": \"text\", \"text\": \"Hi ChatGPT! This is just a test.\" }';\n",
    "    put             ']';\n",
    "    put         '}';\n",
    "    put     ']';\n",
    "    put '}';\n",
    "run;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"Caption\"}\n",
    "Program: Crafting a hard-coded request payload.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "First, the \"model\" parameter specifies which model the prompt will be sent to.\n",
    "There are many different models and they differ primarily in price, capabilities, quality of response, and speed.\n",
    "The \"4o-mini\" model from ChatGPT is very cheap and quite good for most purposes.\n",
    "As of writing, you can see the current list of OpenAI models at https://platform.openai.com/docs/models\n",
    "\n",
    "The other parameter here, \"messages\", is where you'll perform the bulk of prompt customization.\n",
    "This prompt is very simple; it's the equivalent of going to the ChatGPT website and typing a single line.\n",
    "Later on, you'll construct some more interesting prompts.\n",
    "\n",
    "With the request prepared, you can now send it over the web:\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%SAS sas\n",
    "filename response TEMP;\n",
    "\n",
    "/* Make the request... */\n",
    "proc http\n",
    "    url = \"https://api.openai.com/v1/chat/completions\"\n",
    "    method = \"POST\"\n",
    "    ct = \"application/json\"\n",
    "    in = req_json\n",
    "    out = response;\n",
    "    \n",
    "    headers \"Authorization\" = \"Bearer &api_key.\";\n",
    "run;\n",
    "\n",
    "/* ... and then view the response! */\n",
    "data _null_;\n",
    "    infile response length=len;\n",
    "    input line $varying2000. len;\n",
    "    put line;\n",
    "run;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"Caption\"}\n",
    "Figure: Sending a request to ChatGPT and an excerpt from the full response object.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "Much of the request is boilerplate, but make note of the following parameters:\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"List Bullet\"}\n",
    "\"in\" is where to put the request body you constructed\n",
    "\n",
    "\"out\" specifies the file that the response will be written to\n",
    "\n",
    "\"headers\" contains the API key\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "The full response JSON object contains many other interesting items.\n",
    "Feel free to explore them by consulting your chosen platform's documentation.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Your Own API Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "You'll be repeating the above steps many times.\n",
    "Now that you've tried out the basic mechanics, it's worth investing the effort to develop them into reusable program structures.\n",
    "The goal is to not have to think about the plumbing required to send your prompts over the web.\n",
    "To do that, you'll build a simple client compatible with both the ChatGPT and DeepSeek APIs.\n",
    "\n",
    "First, create some small helper macros.\n",
    "They don't do a lot individually, but giving these processes names will help avoid distractions later.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%SAS sas\n",
    "/* Create a file handle and ensure it is fresh. */\n",
    "%macro FileHandle(handle, location=TEMP);\n",
    "    filename &handle. clear; /* Will give warning on first invocation. */\n",
    "    filename &handle. &location.;\n",
    "%mend;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%SAS sas\n",
    "/* Read the contents of a file into a macro variable. */\n",
    "%macro FileContents(variable_name, file_location);\n",
    "    data _null_;\n",
    "        infile &file_location. length=len;\n",
    "        input contents $varying2000. len;\n",
    "        call symputx(&variable_name., contents);\n",
    "    run;\n",
    "%mend;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"Caption\"}\n",
    "Program: Small helper macros for file input and output.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making and Sending Requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "The first major task to tackle is prompt construction.\n",
    "This is a good time to discuss some of the basic prompt elements in more detail.\n",
    "\n",
    "Most prompts consist of a series of messages.\n",
    "Each message consists of some text and a \"role\".\n",
    "The role defines the level of priority the model should give to the message.\n",
    "Some common examples of roles:\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"List Bullet\"}\n",
    "\"system\" - A high-priority background message from the system developer (that's you!)\n",
    "\n",
    "\"user\" - A message from the end user of the application\n",
    "\n",
    "\"assistant\" - A message from model itself\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "You can get creative with how you use the roles.\n",
    "For instance, \"assistant\" is nominally used to store response history when designing a chatbot, but it can be repurposed for few-shot learning.\n",
    "You will see more on that later.\n",
    "\n",
    "Right now, the concern is making it easy to construct prompts from within a SAS program.\n",
    "One simple design is to create a sequence of roles and texts using a data step:\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%SAS sas\n",
    "/* Hardcode the prompt as a dataset. */\n",
    "data my_1st_prompt;\n",
    "    length role $10 text $2000;\n",
    "    input role $ text &:$2000.;\n",
    "    datalines;\n",
    "system You are ChatGPT, a helpful and friendly AI.\n",
    "user Hi ChatGPT!\n",
    "assistant Hello World! What can I do for you?\n",
    "user Can you summarize the significance of the \"Hello world\" example in two sentences?\n",
    ";\n",
    "run;\n",
    "proc print data=my_1st_prompt; run;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"Caption\"}\n",
    "Figure: Demonstrating simple prompt construction using a data step.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "You'll then need a method for turning the prompt data set into a valid JSON payload.\n",
    "This macro is a bit clunky but it gets the job done:\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%SAS sas\n",
    "%macro build_request(\n",
    "    /* Required parameters: */\n",
    "    data,\n",
    "    request_handle,\n",
    "\n",
    "    /* Optional parameters: */\n",
    "    model=\"gpt-4o-mini\",\n",
    "    request_location=TEMP\n",
    ");\n",
    "    %FileHandle(&request_handle., location=&request_location.);\n",
    "    data _null_;\n",
    "        file &request_handle.;\n",
    "\n",
    "        /* Write the opening of the JSON payload. */\n",
    "        put '{';\n",
    "        put     '\"model\": \"' &model. '\",';\n",
    "        put     '\"messages\": [';\n",
    "\n",
    "        /* Loop through the dataset and construct each message block. */\n",
    "        do i = 1 by 1 until (eof);\n",
    "            set &data end=eof;\n",
    "            \n",
    "            /* Escape quotation marks. */\n",
    "            length esc_text $4000;\n",
    "            esc_text = tranwrd(text, '\"', '\\\"');\n",
    "\n",
    "            /* Begin the message object */\n",
    "            put '{';\n",
    "            put     '\"role\": \"' role +(-1) '\",';\n",
    "            put     '\"content\": [';\n",
    "            put         '{ \"type\": \"text\", \"text\": \"' esc_text +(-1) '\" }';\n",
    "            put     ']';\n",
    "\n",
    "            /* End the message object */\n",
    "            if eof then put '}';\n",
    "            else put '},';\n",
    "        end;\n",
    "\n",
    "        /* Close the messages array and the JSON object */\n",
    "        put     ']';\n",
    "        put '}';\n",
    "        stop;\n",
    "    run;\n",
    "%mend;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"Caption\"}\n",
    "Program: Encapsulating the process of building a request object.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "Despite the length of this macro, there's nothing too remarkable about it.\n",
    "Do note that the model name is now an optional parameter, which you can use to try out the various models easily and compare their responses.\n",
    "\n",
    "Having a request object in hand is not very useful without the ability to send it over the web.\n",
    "Take care of that now:\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%SAS sas\n",
    "%macro send_request(\n",
    "    /* Required parameters */\n",
    "    request_handle,\n",
    "    response_handle,\n",
    "    api_key_location,\n",
    "\n",
    "    /* Optional parameters */\n",
    "    service=openai, /* Can pass \"deepseek\" instead with no other changes. */\n",
    "    response_location=TEMP\n",
    ");\n",
    "    %local api_key;\n",
    "    %FileContents(\"api_key\", &api_key_location.);\n",
    "    %FileHandle(&response_handle., location=&response_location.);\n",
    "\n",
    "    /* Make the request. This may take a few seconds to complete. */\n",
    "    proc http\n",
    "        url = \"https://api.&service..com/v1/chat/completions\"\n",
    "        method = \"POST\"\n",
    "        ct = \"application/json\"\n",
    "        in = &request_handle.\n",
    "        out = &response_handle.;\n",
    "        \n",
    "        headers \"Authorization\" = \"Bearer &api_key.\";\n",
    "    run;\n",
    "\n",
    "    /* Results are now stored in response_handle! */\n",
    "\n",
    "%mend;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"Caption\"}\n",
    "Program: Encapsulating sending the request.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "This code should look very familiar.\n",
    "Indeed, it requires virtually no changes from the opening example.\n",
    "The API key now gets freshly loaded each time.\n",
    "\n",
    "Time to put these macros to work!\n",
    "Using the example prompt you constructed earlier, see that the process of building, sending, and receiving data has been made vastly simpler:\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%SAS sas\n",
    "/* Send our prompt to ChatGPT over the network. */\n",
    "%build_request(my_1st_prompt, req_json);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%SAS sas\n",
    "%send_request(req_json, response, \"sources/api_key_chatgpt.txt\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%SAS sas\n",
    "/* Take a peek at the results using the program log.\n",
    " * You could also use a file location on disk instead of TEMP.\n",
    " */\n",
    "data _null_;\n",
    "   rc = jsonpp('response', 'log');\n",
    "run;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"Caption\"}\n",
    "Figure: Demonstrating the API macro suite, with excerpted response.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "Due to their APIs being fully compatible, it's quite simple to call DeepSeek instead of ChatGPT.\n",
    "You need only change the model name, service name, and API key.\n",
    "Here's what that looks like:\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%SAS sas\n",
    "%build_request(my_1st_prompt, req_json, model=\"deepseek-chat\");\n",
    "%send_request(req_json, response, \"sources/api_key_deepseek.txt\", service=deepseek);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"Caption\"}\n",
    "Program: Calling DeepSeek instead of ChatGPT.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refining the Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "You've now got the web plumbing taken care of, but the ergonomics still have room for improvement.\n",
    "First, the prompt construction data step requires enough boilerplate to be annoying.\n",
    "Wrap that up so that prompts can be specified with a macro variable:\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%SAS sas\n",
    "%macro Prompt(name, contents);\n",
    "    data &name.;\n",
    "        length role $20 text $2000;\n",
    "        retain i 1;\n",
    "        do while(scan(\"&contents.\", i, '~') ne '');\n",
    "            line = scan(\"&contents.\", i, '~');\n",
    "            role = scan(line, 1, '|');\n",
    "            text = scan(line, 2, '|');\n",
    "            output;\n",
    "            i + 1;\n",
    "        end;\n",
    "        drop i line;\n",
    "    run;\n",
    "%mend;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"Caption\"}\n",
    "Program: A small utility macro for constructing prompts.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "Now you can write a prompt this way instead!\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%SAS sas\n",
    "%Prompt(my_prompt, %quote(\n",
    "    system|\n",
    "    You are a master Japanese poet specializing in haikus.\n",
    "    Your style is to incorporate mathematical imagery.~\n",
    "    user|Please write a poem about water.\n",
    "));\n",
    "proc print data=my_prompt; run;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"Caption\"}\n",
    "Figure: Constructing a prompt from a macro variable.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "You're almost there!\n",
    "One last piece of missing functionality is actually extracting the messages from the response object.\n",
    "This code is adapted directly from (Mc Cawille 2024), which is also an excellent resource.\n",
    "For even more detail on dealing with JSON objects in SAS, you can also consult (Linker 2019).\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%SAS sas\n",
    "/* Thanks to Stephen Mc Cawille (\"Getting a Prompt Response Using ChatGPT and SAS\") for this code. */\n",
    "%macro extract_response(dataset_name, response_handle, temp_library_handle);\n",
    "    libname &temp_library_handle. JSON fileref = &response_handle.;\n",
    "\n",
    "    data &dataset_name.;\n",
    "        set &temp_library_handle..choices_message;\n",
    "        output;\n",
    "        /*\n",
    "        do row = 1 to max(1, countw(content, '0A'x));\n",
    "            outvar = scan(content, row, '0A'x);\n",
    "            output;\n",
    "        end;\n",
    "        */\n",
    "    run;\n",
    "%mend;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"Caption\"}\n",
    "Program: Pulling the message contents from an API response into a data set.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completing the Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "Now, you're in position to bring everything together into a single macro:\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%SAS sas\n",
    "/* Fully process a raw prompt into a response message. */\n",
    "%macro send_prompt(\n",
    "    /* Required Parameters: */\n",
    "    message_handle,\n",
    "    prompt,\n",
    "    \n",
    "    /* Optional Parameters: */\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_key_location=\"sources/api_key_chatgpt.txt\",\n",
    "    service=openai\n",
    ");\n",
    "    %Prompt(temp_user_prompts, &prompt.);\n",
    "    %build_request(temp_user_prompts, tempreq, model=&model.);\n",
    "    %send_request(tempreq, tempresp, &api_key_location., service=&service.);\n",
    "    %extract_response(&message_handle., tempresp, templib);\n",
    "%mend;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"Caption\"}\n",
    "Program: Implementing an end-to-end API client as a macro.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "As a user, all it takes is to specify your prompt:\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%SAS sas\n",
    "\n",
    "/* Demonstrate simple usage. */\n",
    "%send_prompt(haiku, %quote(\n",
    "    system|\n",
    "    You are a master Japanese poet specializing in haikus, but you do not use\n",
    "    nature references.\n",
    "    Instead, your style is to incorporate mathematical imagery.~\n",
    "    user|Please write a poem about housing policy.\n",
    "));\n",
    "proc print data=haiku; run;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"Caption\"}\n",
    "Figure: Demonstrating use of the end-to-end client.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "You are now in possession of a fully-functional, if basic, ChatGPT/DeepSeek API client built from scratch in SAS!\n",
    "You'll get a chance to put it through its paces in the next section.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can skip the first section entirely and just run this code to load the whole API client at once.\n",
    "\n",
    "import saspy\n",
    "sas = saspy.SASsession(cfgfile='code/env/sascfg.py', results='HTML')\n",
    "\n",
    "# Shortcut to load the full API client\n",
    "with open('code/full_client.sas') as f:\n",
    "    sas.submit(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "Time for the fun stuff!\n",
    "In this second half of the paper, you'll learn how to apply a variety of prompt engineering techniques in the context of a real problem.\n",
    "\n",
    "Despite the fact that language models are inherently nondeterministic black boxes, prompt engineering still has many aspects in common with programming.\n",
    "It's both possible and effective to test, iterate, debug, and sometimes think outside the box as you develop a prompt-based solution.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Case: Date Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "Dates and times seem to always cause for trouble, especially so when it's necessary to impute parts of them.\n",
    "Imputation rules can grow complicated very quickly as corner cases and ambiguities start cropping up.\n",
    "Not to mention that incoming dates and times can vary almost arbitrarily in format.\n",
    "\n",
    "The goal of this exercise is to get a working date imputation prompt suitable for integrating into a data pipeline.\n",
    "That means that not only should the output be accurate and fairly reliable, but also in a standard format conducive for reporting or further processing.\n",
    "\n",
    "Do note, however, that actually integrating the code into a production system is explicitly __not__ an aim of this exercise.\n",
    "The goal is to demonstrate a few techniques and to satisfy an intellectual curiosity, not to recommend an approach for any setting with real stakes.\n",
    "\n",
    "As with any complex task, the key is to start small and focus on one problem element at a time.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Attempt: Prompt Basics and Zero-Shot Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "What's the simplest possible thing that might actually work?\n",
    "Try just asking the model directly!\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%SAS sas\n",
    "%send_prompt(result, %nrstr(\n",
    "    user|\n",
    "    Can you impute the following date for me?\n",
    "    Use the last day of the month if none is specified: February 2024.\n",
    "));\n",
    "proc print data=result; run;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"Caption\"}\n",
    "Figure: A first attempt at date imputation.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "This is an example of what is called \"zero-shot\" prompting, which relies entirely on the model's pretraining (DAIR.AI 2025).\n",
    "Many of the models are already very powerful and you can often get great results with no more effort than this.\n",
    "On the other hand, it can be misleading if it doesn't result in exactly what you wanted right away.\n",
    "It's not necessarily obvious that other techniques are available, but that is what prompt engineering is all about.\n",
    "\n",
    "In this case, it appears that ChatGPT \"understands\" the task correctly and even knows about leap years.\n",
    "However, it spends too many words talking about the result.\n",
    "The goal is to get this integrated into a data processing pipeline and that extra text will just get in the way.\n",
    "\n",
    "This is a good opportunity to exploit some of the other prompt roles that are available.\n",
    "The \"system\" role can often be used to provide general instructions or guidance to the model.\n",
    "Try using a system prompt to control the model's output:\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%SAS sas\n",
    "%send_prompt(result, %nrstr(\n",
    "    system|\n",
    "    The user will ask you for several dates.\n",
    "    You are to apply the specified imputation rules and respond with only the result\n",
    "    of the imputation.~\n",
    "    user|\n",
    "    Can you impute the following date for me?\n",
    "    Use the last day of the month if none is specified: February 2024.\n",
    "));\n",
    "proc print data=result; run;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"Caption\"}\n",
    "Figure: Attempting to use a system prompt to impute dates.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "That actually seems to work great!\n",
    "It's also a good demonstration of a general prompt engineering guideline: prompts should be clear and direct (Anthropic 2025).\n",
    "This system prompt is better than the first attempt in part because it clearly and directly states the desired output format.\n",
    "\n",
    "Of course, it does not suffice to test just one input case.\n",
    "Try another:\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%SAS sas\n",
    "%send_prompt(result, %nrstr(\n",
    "    system|\n",
    "    The user will ask you for several dates.\n",
    "    You are to apply the specified imputation rules and respond with only the result\n",
    "    of the imputation.~\n",
    "    user|\n",
    "    Can you impute the following date for me?\n",
    "    Use the last day of the month if none is specified: May 11 2024.\n",
    "));\n",
    "proc print data=result; run;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"Caption\"}\n",
    "Figure: Attempting to use a system prompt to impute dates, part two.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "Here, the model incorrectly imputes the day even though a full date was specified.\n",
    "It's possible that iterating on the system prompt would be enough to solve this, but there are also many other techniques to try out that might be more effective.\n",
    "\n",
    "As an aside, it will be tedious to continue testing one user input at a time.\n",
    "The remainder of these examples will make use of a testing utility that sends multiple prompts and compiles the results.\n",
    "The full code for the macro is too long and distracting to print here, but it is included in the appendix.\n",
    "Here's how to use it:\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%SAS sas\n",
    "%send_multiple_prompts(\n",
    "    result,\n",
    "    system_prompt=%nrstr(\n",
    "        system|\n",
    "        The user will ask you for several dates.\n",
    "        You are to apply the specified imputation rules and respond with only the result\n",
    "        of the imputation.~\n",
    "        user|\n",
    "        Can you impute the following date for me?\n",
    "        Use the last day of the month if none is specified: ),\n",
    "\n",
    "    user_prompts=%nrstr(February 2024|May 11, 2024|July of 1999|Christmas 2011)\n",
    ");\n",
    "proc print data=result; run;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"Caption\"}\n",
    "Figure: Demonstrating multiple prompts.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teach by Example: Few-Shot Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "Sometimes, the easiest way to get what you want is to demonstrate it.\n",
    "Supplying even a single example can yield a suprising amount of improvement in model performance.\n",
    "Providing examples as part of the prompt is a way to induce contextual learning by the model and is what's referred to as \"few-shot\" prompting (DAIR.AI 2025).\n",
    "\n",
    "In practice, the \"assistant\" role can be used to create example responses.\n",
    "These \"previous\" interactions steer the model towards the desired behaviour.\n",
    "Try an example of this now:\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%SAS sas\n",
    "%send_multiple_prompts(result, system_prompt=%nrstr(\n",
    "    system|\n",
    "    The user will ask you for several dates.\n",
    "    Apply the following rules and respond with only the result of the imputation.\n",
    "    Imputation rules:\n",
    "    1.  If no day is supplied, impute the day to the last day of the month.\n",
    "        Otherwise, use the supplied day. ~\n",
    "    user|February 23, 2024.~\n",
    "    assistant|February 23, 2024~\n",
    "    user|May 2024~\n",
    "    assistant|May 31, 2024~\n",
    "    user|\n",
    "), user_prompts=%nrstr(May 11, 2024|Feb 2023|Independence day 1990|2012 June)\n",
    ");\n",
    "proc print data=result; run;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"Caption\"}\n",
    "Figure: Trying a few-shot prompt.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "As you can see, with only a few examples the model's performance improves dramatically.\n",
    "It even handles the holiday curveball correctly.\n",
    "\n",
    "That's enough toy examples.\n",
    "It's time to get thrown into the deep end.\n",
    "Can you get the model to correctly process significantly more complicated imputation rules?\n",
    "Here is a real set of instructions from a paper about date imputation, adapted into a few-shot prompt (Akinyi 2021):\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%SAS sas\n",
    "%send_multiple_prompts(results, system_prompt=%nrstr(\n",
    "    system|\n",
    "    The user will supply you with several dates regarding event start and end dates.\n",
    "    Apply the following rules to impute the end date of the event.\n",
    "    Respond with only the result of the imputation.\n",
    "    Imputation rules:\n",
    "    1.  For start date: if day is missing then impute to the first day of the month.\n",
    "        If both day and month are missing the impute to 01-Jan.\n",
    "    2.  For end date: if day is missing then impute with last day of that month and\n",
    "        if day and month both are missing then impute with 31-Dec.\n",
    "        If the imputed end date is after the date of death or last known date alive\n",
    "        then set end date to death date if not missing, else set to last known date\n",
    "        alive.\n",
    "    3.  If the year is missing for both start and end dates, then keep as is, no\n",
    "        imputation is required if complete date is missing.~\n",
    "    user|start:2020-03-22, end:2020-03-25, death:2020-08-03, last known alive:2020-05-02~\n",
    "    assistant|2020-03-25~\n",
    "    user|start:2020-03, end: 2020-03, death:2020-08-03, last known alive:2020-05-02~\n",
    "    assistant|2020-03-31~\n",
    "    user|start:2018-12, end: 2019-02, death:2020-08-03, last known alive:2020-05-02~\n",
    "    assistant|2019-02-28~\n",
    "    user|start:2020, end: 2020, death:2020-08-03, last known alive:2020-05-02~\n",
    "    assistant|2020-12-31~\n",
    "    user|),\n",
    "    user_prompts=%nrstr(\n",
    "        start:2020-06,    end: 2020-06,    death:2020-08-03, last known alive:2020-05-02|\n",
    "        start:2020-02,    end: 2020-02,    death:2020-08-03, last known alive:2020-05-02|\n",
    "        start:2020-02,    end: 2020-02,    death:2020-01-13, last known alive:2019-11-27|\n",
    "        start:2018,       end: 2019,       death:2020-01-13, last known alive:2019-11-27|\n",
    "        start:2019-10-30, end: 2019-11,    death:2020-01-13, last known alive:2019-11-27|\n",
    "        start:2019-10-30, end: 2019-11-12, death:2020-01-13, last known alive:2019-11-27\n",
    "    )\n",
    ");\n",
    "proc print data=results; run;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"Caption\"}\n",
    "Figure: Trying a real-world date imputation scenario.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "All of the \"training\" cases and the first two user cases are from the source paper.\n",
    "The model correctly imputes the source paper's user cases and manages to adapt to a different set of death and last-known-alive dates.\n",
    "However, it starts to fall down for the more complex cases where the imputed event date is after last-known-alive but before death.\n",
    "Also, it is again incorrectly imputing complete dates.\n",
    "\n",
    "You can (and should!) try a few approaches based on the topics covered so far:\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"List Bullet\"}\n",
    "Make the system prompt more clear and direct about what to do in the ambiguous cases.\n",
    "\n",
    "Provide more examples that cover all of the possibilities.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "However, sometimes these techniques won't suffice, or the resulting system will be unreliable.\n",
    "It's also not ideal to just guess-and-check your way through refining the prompt.\n",
    "The next two techniques can help with both seeing what the model is doing and ensuring that it follows complex instructions without dropping the ball.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Think it Through: Chain-of-Thought and Prompt Chaining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "As you've just seen, it can be difficult to get the model to follow all of the rules correctly when working on more complicated tasks.\n",
    "If the model could explain what it is thinking, that would likely help significantly in diagnosing the issue.\n",
    "\n",
    "As a matter of fact, you can do just that!\n",
    "The concept of chain-of-thought prompting is to have the model explain its reasoning to itself.\n",
    "Somehow, this seems to help, though exactly _why_ it helps is not well understood.\n",
    "It's thought that this ability is an emergent property of models with sufficiently many parameters (DAIR.AI 2025).\n",
    "\n",
    "Try it with a simpler version of the last prompt.\n",
    "Notice how the system prompt has changed to emphasize the thinking process rather than the final output:\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%SAS sas\n",
    "%send_multiple_prompts(results, system_prompt=%nrstr(\n",
    "    system|\n",
    "    The user will supply you with several dates regarding event start and end dates.\n",
    "    First, think carefully about which rules apply for the input.\n",
    "    In particular, decide if any imputation is required at all.\n",
    "    Then, if imputation is needed, note where the end date falls relative to the death\n",
    "    and last known alive dates.\n",
    "    State how the end date should be imputed based on this information.\n",
    "    Finally, state the correct result of the imputation.\n",
    "    Imputation rules:\n",
    "    1.  For start date: if day is missing then impute to the first day of the month.\n",
    "        If both day and month are missing the impute to 01-Jan.\n",
    "    2.  For end date: if day is missing then impute with last day of that month and\n",
    "        if day and month both are missing then impute with 31-Dec.\n",
    "        If the imputed end date is after the date of death or last known date alive\n",
    "        then set end date to death date if not missing, else set to last known date\n",
    "        alive.\n",
    "    3.  If the year is missing for both start and end dates, then keep as is, no\n",
    "        imputation is required if complete date is missing.~\n",
    "    user|),\n",
    "    user_prompts=%nrstr(\n",
    "        start:2020-06,    end: 2020-06,    death:2020-08-03, last known alive:2020-05-02|\n",
    "        start:2018,       end: 2019,       death:2020-01-13, last known alive:2019-11-27|\n",
    "        start:2019-10-30, end: 2019-11,    death:2020-01-13, last known alive:2019-11-27|\n",
    "        start:2019-10-30, end: 2019-11-12, death:2020-01-13, last known alive:2019-11-27\n",
    "    )\n",
    ");\n",
    "proc print data=results; run;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"Caption\"}\n",
    "Figure: Demonstrating chain of thought reasoning.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "Aha!\n",
    "This output is very revealing.\n",
    "The model clearly states its reasoning step by step and its final answers are coherent with their respecitve explanations.\n",
    "\n",
    "This is great feedback for adjusting the prompt.\n",
    "For instance, if, say, case 3 should have been imputed to the date of death, it's clear how to adjust the prompt to get this outcome.\n",
    "You can now go back to the original prompt and revise the rules to be more direct and/or supply additional examples.\n",
    "\n",
    "This prompt seems to also fix the problem with imputing complete dates even though it doesn't provide any examples.\n",
    "Different prompting techniques can be somewhat interchangeable.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "Now what if, rather than going back and revising the earlier prompt, you want to use this style directly in the application?\n",
    "Chain-of-thought is often highly effective but it does result in a lot of output clutter.\n",
    "This is where prompt chaining comes in.\n",
    "\n",
    "The idea behind prompt chaining is to break down a task into multiple prompts specialized for a distinct step in the process (Anthropic 2025).\n",
    "You do not try to force the model to handle the entire job in one go.\n",
    "Instead, you design a logical sequence of prompts such that the output of one can be fed directly to another.\n",
    "For instance, after applying the reasoning step, you can do something like this:\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%SAS sas\n",
    "%send_multiple_prompts(results, system_prompt=%nrstr(\n",
    "    system|\n",
    "    The user will supply you with a long chain of reasoning about a date imputation.\n",
    "    Your job is to extract _only_ the final result for the \"end date\" and print it by\n",
    "    itself. It is very likely that the target date will be at the very end of the text.\n",
    "    Use ISO 8601 formatting.~\n",
    "    user|),\n",
    "    user_prompts=%nrstr(<<<FULL TEXT OMITTED FOR BREVITY>>>)\n",
    ");\n",
    "proc print data=results; run;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"Caption\"}\n",
    "Figure: Using a prompt chain to extract the final answer.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "That demonstrates the idea.\n",
    "The next step would be to automatically extract the response from the first prompt and feed it directly into the second prompt without having to copy and paste.\n",
    "This is left as an exercise to the reader.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where to Go Next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "Hopefully, this introduction has been sufficient to whet your appetite!\n",
    "There are many details that were glossed over which are worth your time to investigate further, including:\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"List Bullet\"}\n",
    "Other prompt parameters: temperature, \"top p\", stop sequences, etc.\n",
    "\n",
    "Using a prompt generator\n",
    "\n",
    "Comparing performance and speed between models\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "<br/>\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "There are also many advanced topics in prompt engineering.\n",
    "To provide a sample:\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"List Bullet\"}\n",
    "Use of images and audio in prompts\n",
    "\n",
    "Structured outputs (automatic JSON formatting of responses)\n",
    "\n",
    "Tree-of-thoughts prompting\n",
    "\n",
    "Meta prompting\n",
    "\n",
    "Model fine-tuning\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "<br/>\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "There is plenty to explore!\n",
    "The user and prompting guides in the references are good places to get started, in addition to the API documentation itself.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "You have now built a working SAS API client!\n",
    "You are now also familiar with the basics of prompt engineering and have a sense of how to apply its principles.\n",
    "The world of language models is your oyster.\n",
    "\n",
    "There is no better way to learn about both the capabilities and limitations of language models than to try to solve problems with them.\n",
    "There is a lot of hype that grows unimpeded in the imagination but collapses entirely after a moment's experimentation.\n",
    "At the same time, these models continue to surprise even their most practiced users with unanticipated abilities.\n",
    "It is a magical time to be learning about and with this technology.\n",
    "Make the most of it!\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sas.endsas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Github Repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "This paper is available as a Jupyter notebook.\n",
    "Clone or fork the repo on github at https://github.com/austrowj/psug2025-chatgpt-in-sas (don't forget to star! )\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical Resources "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "\n",
    "OpenAI API Documentation: \\\n",
    "https://platform.openai.com/docs/api-reference/introduction\n",
    "\n",
    "DeepSeek API Documentation: \\\n",
    "https://api-docs.deepseek.com/\n",
    "\n",
    "Tidyverse ellmer - Call LLM APIs from R: \\\n",
    "https://github.com/tidyverse/ellmer\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General LLM Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "\n",
    "Skliar, Illia. 2023.\n",
    "\"Boosting SAS Programming Efficiency with ChatGPT: A Clinical Trials Perspective.\"\n",
    "PHUSE Connect EU 2023.\n",
    "Available at https://www.lexjansen.com/phuse/2023/cm/PAP_CM04.pdf\n",
    "\n",
    "Sturdy, Ian. 2024.\n",
    "\"Leveraging ChatGPT in Statistical Programming in the Pharmaceutical Industry.\"\n",
    "PharmaSUG 2024.\n",
    "Available at https://www.lexjansen.com/pharmasug/2024/AP/PharmaSUG-2024-AP-256.pdf\n",
    "\n",
    "Tarap, Karma. 2023.\n",
    "\"LLMs Unleashed: A New Chapter in Clinical Programming?\"\n",
    "PHUSE Connect 2023.\n",
    "Available at https://www.lexjansen.com/phuse/2023/cm/PAP_CM07.pdf\n",
    "\n",
    "Vysotskyi, Mykyta. 2024.\n",
    "\"Navigating the Safe Integration of AI (ChatGPT) into Clinical Trials Programming Workflow.\"\n",
    "PHUSE Connect US 2024.\n",
    "Available at https://www.lexjansen.com/phuse-us/2024/et/PAP_ET09.pdf\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "\n",
    "Akinyi, Teckla. 2021.\n",
    "\"Common Dating in R: With an example of partial date imputation.\"\n",
    "PharmaSUG 2021.\n",
    "Available at https://pharmasug.org/proceedings/2021/QT/PharmaSUG-2021-QT-139.pdf\n",
    "\n",
    "Henry, Joseph. 2019.\n",
    "\"The ABCs of PROC HTTP.\"\n",
    "SAS Global Forum 2019.\n",
    "Available at https://support.sas.com/resources/papers/proceedings19/3232-2019.pdf\n",
    "\n",
    "Linker, Adam. 2019.\n",
    "\"Creating and Controlling JSON Output with the JSON Procedure.\"\n",
    "SAS Global Forum 2019.\n",
    "Available at https://support.sas.com/resources/papers/proceedings19/3506-2019.pdf\n",
    "\n",
    "Mc Cawille, Stephen. 2024.\n",
    "\"Getting a Prompt Response Using ChatGPT and SAS.\"\n",
    "PHUSE EU Connect 2024.\n",
    "Available at https://phuse.s3.eu-central-1.amazonaws.com/Archive/2024/Connect/EU/Strasbourg/PAP_CT02.pdf\n",
    "\n",
    "Anthropic. 2025.\n",
    "\"Claude User Guide.\"\n",
    "Accessed 30 March 2025.\n",
    "https://docs.anthropic.com/en/docs/welcome\n",
    "\n",
    "DAIR.AI. 2025.\n",
    "\"Prompting Guide.\"\n",
    "Accessed 30 March 2025.\n",
    "https://www.promptingguide.ai/\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|PAGEBREAK|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contact Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "Your comments and questions are valued and encouraged. Contact the author at:\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"AddressBlock\"}\n",
    "James Austrow\n",
    "\n",
    "Cleveland Clinic\n",
    "\n",
    "austroj AT ccf DOT org\n",
    "    \n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"PaperBody\"}\n",
    "<br/>\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {custom-style=\"Style PaperBody + Calibri 11 pt Black\"}\n",
    "\n",
    "Any brand and product names are trademarks of their respective companies. \n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|PAGEBREAK|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: Multiple Prompts Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%SAS sas\n",
    "%macro send_multiple_prompts(output_ds, system_prompt=, user_prompts=);\n",
    "\n",
    "    /* Clean up the output dataset if it exists */\n",
    "    proc datasets lib=work nolist;\n",
    "        delete &output_ds;\n",
    "    quit;\n",
    "\n",
    "    %let i = 1;\n",
    "    %let single_prompt = %scan(&user_prompts, &i, |);\n",
    "\n",
    "    %do %while(%length(&single_prompt));\n",
    "\n",
    "        /* Build the full prompt for this iteration */\n",
    "        %let full_prompt = &system_prompt.&single_prompt;\n",
    "\n",
    "        /* Temporary dataset for each iteration */\n",
    "        %let temp_ds = _tmp_resp_&i;\n",
    "\n",
    "        %put &full_prompt.;\n",
    "\n",
    "        /* Call the existing %send_prompt macro */\n",
    "        %send_prompt(&temp_ds, %superq(full_prompt));\n",
    "\n",
    "        /* Add a variable for the user prompt */\n",
    "        data &temp_ds;\n",
    "            length user_prompt $2000;\n",
    "            set &temp_ds;\n",
    "            user_prompt = \"&single_prompt\";\n",
    "        run;\n",
    "\n",
    "        /* Append this result to the compilation output dataset */\n",
    "        %if &i = 1 %then %do;\n",
    "            data &output_ds;\n",
    "                length user_prompt $2000 content $2000;\n",
    "                set &temp_ds;\n",
    "                keep user_prompt content;\n",
    "            run;\n",
    "        %end;\n",
    "        %else %do;\n",
    "            proc append base=&output_ds data=&temp_ds force; run;\n",
    "        %end;\n",
    "\n",
    "        /* Move to the next prompt */\n",
    "        %let i = %eval(&i + 1);\n",
    "        %let single_prompt = %scan(&user_prompts, &i, |);\n",
    "\n",
    "    %end;\n",
    "\n",
    "    /* Reorder for clarity: user prompt first, then response */\n",
    "    data &output_ds;\n",
    "        retain user_prompt;\n",
    "        set &output_ds;\n",
    "    run;\n",
    "\n",
    "%mend;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
